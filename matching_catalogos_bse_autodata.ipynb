{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agmCorp/colab/blob/main/matching_catalogos_bse_autodata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-8asNb1v9DU"
      },
      "source": [
        "# Sistema de Matching Inteligente: BSE vs Autodata\n",
        "## Soluci√≥n basada en Embeddings Sem√°nticos (Sentence-BERT)\n",
        "\n",
        "**Objetivo:** Identificar autom√°ticamente qu√© modelos de Autodata ya existen en el cat√°logo BSE\n",
        "\n",
        "**Criterios de clasificaci√≥n:**\n",
        "- **YA EXISTE** ‚Üí score > 0.75\n",
        "- **REVISI√ìN HUMANA** ‚Üí 0.6 ‚â§ score ‚â§ 0.75\n",
        "- **ALTA NECESARIA** ‚Üí score < 0.6\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7NYKbNQv9DW"
      },
      "source": [
        "## 1Ô∏è‚É£ Instalaci√≥n de dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8cGVOuBv9DW"
      },
      "outputs": [],
      "source": [
        "# Instalar librer√≠as necesarias\n",
        "!pip install -q sentence-transformers pandas numpy scikit-learn unidecode tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK3q5P_Uv9DX"
      },
      "source": [
        "## 2Ô∏è‚É£ Importar librer√≠as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aqx3mKPtv9DX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from unidecode import unidecode\n",
        "import re\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Librer√≠as importadas correctamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR96_ywjv9DY"
      },
      "source": [
        "## 3Ô∏è‚É£ Cargar los archivos CSV\n",
        "\n",
        "**Importante:** Sube los archivos en la secci√≥n de archivos de Colab:\n",
        "- `CART_MATRICERO_BSE_202602031858.csv`\n",
        "- `CART_PAD_AUTODATA_202602031856.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyxupIjtv9DY"
      },
      "outputs": [],
      "source": [
        "# Cargar los datos\n",
        "df_bse = pd.read_csv('/content/sample_data/CART_MATRICERO_BSE_202602031858.csv')\n",
        "df_autodata = pd.read_csv('/content/sample_data/CART_PAD_AUTODATA_202602031856.csv')\n",
        "\n",
        "print(f\"Registros BSE: {len(df_bse):,}\")\n",
        "print(f\"Registros Autodata: {len(df_autodata):,}\")\n",
        "print(\"\\nPrimeras filas de BSE:\")\n",
        "display(df_bse.head(3))\n",
        "print(\"\\nPrimeras filas de Autodata:\")\n",
        "display(df_autodata.head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeKhuJ35v9DZ"
      },
      "source": [
        "## 4Ô∏è‚É£ Funciones de Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORrKa8Mzv9DZ"
      },
      "outputs": [],
      "source": [
        "def normalizar_texto(texto):\n",
        "    \"\"\"\n",
        "    Normaliza texto removiendo acentos, convirtiendo a min√∫sculas,\n",
        "    y eliminando caracteres especiales excepto espacios y n√∫meros.\n",
        "    \"\"\"\n",
        "    if pd.isna(texto):\n",
        "        return \"\"\n",
        "    # Convertir a string y min√∫sculas\n",
        "    texto = str(texto).lower()\n",
        "    # Remover acentos\n",
        "    texto = unidecode(texto)\n",
        "    # Remover caracteres especiales pero mantener espacios y n√∫meros\n",
        "    texto = re.sub(r'[^a-z0-9\\s]', ' ', texto)\n",
        "    # Normalizar espacios m√∫ltiples\n",
        "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
        "    return texto\n",
        "\n",
        "\n",
        "def normalizar_marca(marca):\n",
        "    \"\"\"\n",
        "    Normaliza marcas removiendo sufijos como <BRA>, <COR>, etc.\n",
        "    y estandarizando variantes comunes.\n",
        "    \"\"\"\n",
        "    marca_norm = normalizar_texto(marca)\n",
        "    # Remover sufijos entre <>\n",
        "    marca_norm = re.sub(r'<[^>]+>', '', marca_norm).strip()\n",
        "\n",
        "    # Diccionario de variantes comunes\n",
        "    variantes = {\n",
        "        'volkswagen': 'vw',\n",
        "        'mercedes benz': 'mercedes',\n",
        "        'land rover': 'landrover',\n",
        "        'chevrolet': 'chevy',\n",
        "    }\n",
        "\n",
        "    for original, abrev in variantes.items():\n",
        "        if original in marca_norm:\n",
        "            marca_norm = abrev\n",
        "\n",
        "    return marca_norm\n",
        "\n",
        "\n",
        "def extraer_anio_inicio_fin(rango_anios):\n",
        "    \"\"\"\n",
        "    Extrae a√±o de inicio y fin de un rango como \"2020 - 2023\"\n",
        "    Retorna (a√±o_inicio, a√±o_fin)\n",
        "    \"\"\"\n",
        "    if pd.isna(rango_anios):\n",
        "        return None, None\n",
        "\n",
        "    rango_str = str(rango_anios).strip()\n",
        "    # Buscar patrones como \"2020 - 2023\" o \"2020-2023\"\n",
        "    match = re.search(r'(\\d{4})\\s*-\\s*(\\d{4})', rango_str)\n",
        "    if match:\n",
        "        return int(match.group(1)), int(match.group(2))\n",
        "\n",
        "    # Si es un a√±o suelto\n",
        "    match = re.search(r'(\\d{4})', rango_str)\n",
        "    if match:\n",
        "        anio = int(match.group(1))\n",
        "        return anio, anio\n",
        "\n",
        "    return None, None\n",
        "\n",
        "\n",
        "def anio_en_rango(anio_puntual, anio_inicio, anio_fin):\n",
        "    \"\"\"\n",
        "    Verifica si un a√±o puntual est√° dentro de un rango.\n",
        "    \"\"\"\n",
        "    if anio_inicio is None or anio_fin is None or anio_puntual is None:\n",
        "        return False\n",
        "    return anio_inicio <= anio_puntual <= anio_fin\n",
        "\n",
        "\n",
        "print(\"Funciones de preprocesamiento definidas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21uFfU29v9Da"
      },
      "source": [
        "## 5Ô∏è‚É£ Preprocesamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZMFXDuav9Da"
      },
      "outputs": [],
      "source": [
        "# Preprocesar BSE\n",
        "df_bse['marca_norm'] = df_bse['MARCA'].apply(normalizar_marca)\n",
        "df_bse['modelo_norm'] = df_bse['MODELO'].apply(normalizar_texto)\n",
        "df_bse[['anio_inicio', 'anio_fin']] = df_bse['RANGO_ANIOS'].apply(\n",
        "    lambda x: pd.Series(extraer_anio_inicio_fin(x))\n",
        ")\n",
        "\n",
        "# Preprocesar Autodata\n",
        "df_autodata['marca_norm'] = df_autodata['MARCA_A'].apply(normalizar_marca)\n",
        "df_autodata['modelo_norm'] = df_autodata['MODELO_A'].apply(normalizar_texto)\n",
        "df_autodata['anio'] = df_autodata['ANIO_A'].astype(int)\n",
        "\n",
        "print(\"Datos preprocesados\")\n",
        "print(f\"\\nBSE v√°lidos (con a√±os): {df_bse[df_bse['anio_inicio'].notna()].shape[0]:,}\")\n",
        "print(f\"Autodata v√°lidos: {len(df_autodata):,}\")\n",
        "\n",
        "# Eliminar registros sin informaci√≥n de a√±os en BSE\n",
        "df_bse = df_bse[df_bse['anio_inicio'].notna()].copy()\n",
        "\n",
        "print(\"\\nEjemplo de preprocesamiento:\")\n",
        "print(\"\\nBSE:\")\n",
        "display(df_bse[['MARCA', 'marca_norm', 'MODELO', 'modelo_norm', 'RANGO_ANIOS', 'anio_inicio', 'anio_fin']].head(3))\n",
        "print(\"\\nAutodata:\")\n",
        "display(df_autodata[['MARCA_A', 'marca_norm', 'MODELO_A', 'modelo_norm', 'ANIO_A', 'anio']].head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-daU9lpv9Da"
      },
      "source": [
        "## 6Ô∏è‚É£ Cargar modelo de Sentence-BERT\n",
        "\n",
        "Usaremos **paraphrase-multilingual-MiniLM-L12-v2** que:\n",
        "- Soporta espa√±ol\n",
        "- Es r√°pido (384 dimensiones)\n",
        "- Captura similitud sem√°ntica efectivamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkU8gV_dv9Db"
      },
      "outputs": [],
      "source": [
        "# Cargar modelo de embeddings\n",
        "print(\"Cargando modelo Sentence-BERT...\")\n",
        "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "print(\"Modelo cargado exitosamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL2PuZANv9Db"
      },
      "source": [
        "## 7Ô∏è‚É£ Generar embeddings para BSE (una sola vez)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE84-LF9v9Db"
      },
      "outputs": [],
      "source": [
        "# Generar embeddings para todos los modelos de BSE\n",
        "print(\"Generando embeddings para cat√°logo BSE...\")\n",
        "print(f\"Total de modelos: {len(df_bse):,}\")\n",
        "\n",
        "# Crear texto combinado para mejor contexto\n",
        "df_bse['texto_embedding'] = df_bse['marca_norm'] + ' ' + df_bse['modelo_norm']\n",
        "\n",
        "# Generar embeddings en lotes para eficiencia\n",
        "batch_size = 128\n",
        "bse_embeddings = model.encode(\n",
        "    df_bse['texto_embedding'].tolist(),\n",
        "    batch_size=batch_size,\n",
        "    show_progress_bar=True,\n",
        "    convert_to_tensor=False\n",
        ")\n",
        "\n",
        "print(f\"\\nEmbeddings generados: {bse_embeddings.shape}\")\n",
        "print(f\"Dimensiones: {bse_embeddings.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgfi3FuQv9Dc"
      },
      "source": [
        "## 8Ô∏è‚É£ Funci√≥n principal de matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXit1Scxv9Dc"
      },
      "outputs": [],
      "source": [
        "def encontrar_matches(row_autodata, df_bse, bse_embeddings, model, top_k=3):\n",
        "    \"\"\"\n",
        "    Encuentra los mejores matches para un registro de Autodata.\n",
        "\n",
        "    Retorna:\n",
        "    - Lista de diccionarios con top_k candidatos\n",
        "    - Cada candidato incluye: ID_AUTODATA_BSE, score, marca, modelo, rango\n",
        "    \"\"\"\n",
        "    marca_auto = row_autodata['marca_norm']\n",
        "    anio_auto = row_autodata['anio']\n",
        "    modelo_auto = row_autodata['modelo_norm']\n",
        "\n",
        "    # PASO 1: Filtrar por marca exacta (o muy similar)\n",
        "    mask_marca = df_bse['marca_norm'] == marca_auto\n",
        "\n",
        "    # Si no hay coincidencias exactas, buscar marcas similares\n",
        "    if mask_marca.sum() == 0:\n",
        "        # Buscar marcas que contengan la marca buscada o viceversa\n",
        "        mask_marca = df_bse['marca_norm'].apply(\n",
        "            lambda x: marca_auto in x or x in marca_auto\n",
        "        )\n",
        "\n",
        "    # PASO 2: Filtrar por a√±o dentro del rango\n",
        "    mask_anio = df_bse.apply(\n",
        "        lambda x: anio_en_rango(anio_auto, x['anio_inicio'], x['anio_fin']),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Combinar filtros\n",
        "    mask_candidatos = mask_marca & mask_anio\n",
        "\n",
        "    # Si no hay candidatos con marca Y a√±o, relajar a solo marca\n",
        "    if mask_candidatos.sum() == 0:\n",
        "        mask_candidatos = mask_marca\n",
        "\n",
        "    # Si a√∫n no hay candidatos, retornar sin matches\n",
        "    if mask_candidatos.sum() == 0:\n",
        "        return []\n",
        "\n",
        "    # PASO 3: Calcular similitud sem√°ntica solo con candidatos filtrados\n",
        "    indices_candidatos = df_bse[mask_candidatos].index.tolist()\n",
        "    embeddings_candidatos = bse_embeddings[indices_candidatos]\n",
        "\n",
        "    # Generar embedding para el modelo de Autodata\n",
        "    texto_autodata = marca_auto + ' ' + modelo_auto\n",
        "    embedding_autodata = model.encode(texto_autodata, convert_to_tensor=False)\n",
        "\n",
        "    # Calcular similitud coseno\n",
        "    similitudes = util.cos_sim(embedding_autodata, embeddings_candidatos)[0].numpy()\n",
        "\n",
        "    # PASO 4: Aplicar bonificaci√≥n por coincidencia exacta de marca y a√±o\n",
        "    scores_ajustados = []\n",
        "    for i, idx_bse in enumerate(indices_candidatos):\n",
        "        score_base = float(similitudes[i])\n",
        "\n",
        "        # Bonificaci√≥n por marca exacta\n",
        "        if df_bse.loc[idx_bse, 'marca_norm'] == marca_auto:\n",
        "            score_base *= 1.05  # +5%\n",
        "\n",
        "        # Bonificaci√≥n por a√±o en rango\n",
        "        if anio_en_rango(anio_auto, df_bse.loc[idx_bse, 'anio_inicio'],\n",
        "                        df_bse.loc[idx_bse, 'anio_fin']):\n",
        "            score_base *= 1.10  # +10%\n",
        "\n",
        "        # Normalizar a m√°ximo 1.0\n",
        "        score_final = min(score_base, 1.0)\n",
        "        scores_ajustados.append(score_final)\n",
        "\n",
        "    # PASO 5: Ordenar y seleccionar top K\n",
        "    top_indices = np.argsort(scores_ajustados)[::-1][:top_k]\n",
        "\n",
        "    resultados = []\n",
        "    for i in top_indices:\n",
        "        idx_bse = indices_candidatos[i]\n",
        "        score = scores_ajustados[i]\n",
        "\n",
        "        resultados.append({\n",
        "            'ID_AUTODATA_BSE': df_bse.loc[idx_bse, 'ID_AUTODATA_BSE'],\n",
        "            'score': score,\n",
        "            'marca_bse': df_bse.loc[idx_bse, 'MARCA'],\n",
        "            'modelo_bse': df_bse.loc[idx_bse, 'MODELO'],\n",
        "            'rango_anios_bse': df_bse.loc[idx_bse, 'RANGO_ANIOS']\n",
        "        })\n",
        "\n",
        "    return resultados\n",
        "\n",
        "\n",
        "def clasificar_resultado(score, umbral_existe=0.75, umbral_alta=0.60):\n",
        "    \"\"\"\n",
        "    Clasifica el resultado basado en el score y umbrales.\n",
        "    \"\"\"\n",
        "    if score >= umbral_existe:\n",
        "        return 'YA_EXISTE'\n",
        "    elif score < umbral_alta:\n",
        "        return 'ALTA_NECESARIA'\n",
        "    else:\n",
        "        return 'REVISION_HUMANA'\n",
        "\n",
        "\n",
        "print(\"Funciones de matching definidas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_8ngLyev9Dc"
      },
      "source": [
        "## 9Ô∏è‚É£ Ejecutar matching para todo el cat√°logo Autodata\n",
        "\n",
        "**NOTA:** Este proceso puede tomar varios minutos dependiendo del tama√±o del cat√°logo. Usar GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMcqJ78Cv9Dd"
      },
      "outputs": [],
      "source": [
        "# Par√°metros de clasificaci√≥n\n",
        "UMBRAL_EXISTE = 0.75\n",
        "UMBRAL_ALTA = 0.60\n",
        "TOP_K = 3\n",
        "\n",
        "print(\"Iniciando proceso de matching...\")\n",
        "print(f\"Umbrales: YA_EXISTE > {UMBRAL_EXISTE}, ALTA_NECESARIA < {UMBRAL_ALTA}\")\n",
        "print(f\"Candidatos por registro: Top {TOP_K}\\n\")\n",
        "\n",
        "# Lista para almacenar resultados\n",
        "resultados_finales = []\n",
        "\n",
        "# Procesar cada registro de Autodata\n",
        "for idx, row in tqdm(df_autodata.iterrows(), total=len(df_autodata), desc=\"Procesando\"):\n",
        "    # Encontrar matches\n",
        "    matches = encontrar_matches(row, df_bse, bse_embeddings, model, top_k=TOP_K)\n",
        "\n",
        "    # Preparar resultado para este registro\n",
        "    if len(matches) == 0:\n",
        "        # Sin candidatos\n",
        "        resultado = {\n",
        "            'ID_AUTADATA': row['ID_AUTADATA'],\n",
        "            'MARCA_A': row['MARCA_A'],\n",
        "            'MODELO_A': row['MODELO_A'],\n",
        "            'ANIO_A': row['ANIO_A'],\n",
        "            'DECISION': 'ALTA_NECESARIA',\n",
        "            'SCORE_MEJOR': 0.0,\n",
        "            'ID_AUTODATA_BSE_MEJOR': None,\n",
        "            'MARCA_BSE_MEJOR': None,\n",
        "            'MODELO_BSE_MEJOR': None,\n",
        "            'RANGO_ANIOS_BSE_MEJOR': None,\n",
        "        }\n",
        "\n",
        "        # Candidatos alternos (vac√≠os)\n",
        "        for i in range(1, TOP_K):\n",
        "            resultado[f'SCORE_CANDIDATO_{i+1}'] = None\n",
        "            resultado[f'ID_AUTODATA_BSE_CANDIDATO_{i+1}'] = None\n",
        "            resultado[f'MODELO_BSE_CANDIDATO_{i+1}'] = None\n",
        "\n",
        "    else:\n",
        "        # Hay candidatos - tomar el mejor\n",
        "        mejor_match = matches[0]\n",
        "        decision = clasificar_resultado(mejor_match['score'], UMBRAL_EXISTE, UMBRAL_ALTA)\n",
        "\n",
        "        resultado = {\n",
        "            'ID_AUTADATA': row['ID_AUTADATA'],\n",
        "            'MARCA_A': row['MARCA_A'],\n",
        "            'MODELO_A': row['MODELO_A'],\n",
        "            'ANIO_A': row['ANIO_A'],\n",
        "            'DECISION': decision,\n",
        "            'SCORE_MEJOR': round(mejor_match['score'], 4),\n",
        "            'ID_AUTODATA_BSE_MEJOR': mejor_match['ID_AUTODATA_BSE'],\n",
        "            'MARCA_BSE_MEJOR': mejor_match['marca_bse'],\n",
        "            'MODELO_BSE_MEJOR': mejor_match['modelo_bse'],\n",
        "            'RANGO_ANIOS_BSE_MEJOR': mejor_match['rango_anios_bse'],\n",
        "        }\n",
        "\n",
        "        # A√±adir candidatos alternos\n",
        "        for i in range(1, TOP_K):\n",
        "            if i < len(matches):\n",
        "                resultado[f'SCORE_CANDIDATO_{i+1}'] = round(matches[i]['score'], 4)\n",
        "                resultado[f'ID_AUTODATA_BSE_CANDIDATO_{i+1}'] = matches[i]['ID_AUTODATA_BSE']\n",
        "                resultado[f'MODELO_BSE_CANDIDATO_{i+1}'] = matches[i]['modelo_bse']\n",
        "            else:\n",
        "                resultado[f'SCORE_CANDIDATO_{i+1}'] = None\n",
        "                resultado[f'ID_AUTODATA_BSE_CANDIDATO_{i+1}'] = None\n",
        "                resultado[f'MODELO_BSE_CANDIDATO_{i+1}'] = None\n",
        "\n",
        "    resultados_finales.append(resultado)\n",
        "\n",
        "# Convertir a DataFrame\n",
        "df_resultados = pd.DataFrame(resultados_finales)\n",
        "\n",
        "print(\"\\nMatching completado!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5uZ-2Y_v9Dd"
      },
      "source": [
        "## üîü An√°lisis de Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUGklPEvv9Dd"
      },
      "outputs": [],
      "source": [
        "# Resumen estad√≠stico\n",
        "print(\"=\"*70)\n",
        "print(\"RESUMEN DE RESULTADOS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "decisiones_conteo = df_resultados['DECISION'].value_counts()\n",
        "total = len(df_resultados)\n",
        "\n",
        "print(f\"\\nTotal de registros procesados: {total:,}\\n\")\n",
        "\n",
        "for decision, count in decisiones_conteo.items():\n",
        "    porcentaje = (count / total) * 100\n",
        "    simbolo = {'YA_EXISTE': '‚úÖ', 'ALTA_NECESARIA': 'üÜï', 'REVISION_HUMANA': '‚ö†Ô∏è'}.get(decision, '‚ùì')\n",
        "    print(f\"{simbolo} {decision:20s}: {count:6,} ({porcentaje:5.2f}%)\")\n",
        "\n",
        "# Distribuci√≥n de scores\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DISTRIBUCI√ìN DE SCORES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "scores = df_resultados['SCORE_MEJOR'].dropna()\n",
        "if len(scores) > 0:\n",
        "    print(f\"\\nEstad√≠sticas de similitud:\")\n",
        "    print(f\"Media:    {scores.mean():.4f}\")\n",
        "    print(f\"Mediana:  {scores.median():.4f}\")\n",
        "    print(f\"Desv.Std: {scores.std():.4f}\")\n",
        "    print(f\"M√≠nimo:   {scores.min():.4f}\")\n",
        "    print(f\"M√°ximo:   {scores.max():.4f}\")\n",
        "\n",
        "    # Percentiles\n",
        "    print(f\"\\nPercentil 25: {scores.quantile(0.25):.4f}\")\n",
        "    print(f\"Percentil 50: {scores.quantile(0.50):.4f}\")\n",
        "    print(f\"Percentil 75: {scores.quantile(0.75):.4f}\")\n",
        "    print(f\"Percentil 90: {scores.quantile(0.90):.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVockoy5v9De"
      },
      "source": [
        "## 1Ô∏è‚É£1Ô∏è‚É£ Ejemplos de cada categor√≠a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrKGJfaHv9De"
      },
      "outputs": [],
      "source": [
        "# Mostrar ejemplos de YA_EXISTE\n",
        "print(\"=\"*100)\n",
        "print(\"EJEMPLOS DE 'YA EXISTE' (score > 0.75)\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "ya_existe = df_resultados[df_resultados['DECISION'] == 'YA_EXISTE'].sort_values('SCORE_MEJOR', ascending=False).head(5)\n",
        "if len(ya_existe) > 0:\n",
        "    for idx, row in ya_existe.iterrows():\n",
        "        print(f\"\\nScore: {row['SCORE_MEJOR']:.4f}\")\n",
        "        print(f\"Autodata: {row['MARCA_A']} | {row['MODELO_A']} | {row['ANIO_A']}\")\n",
        "        print(f\"BSE:      {row['MARCA_BSE_MEJOR']} | {row['MODELO_BSE_MEJOR']} | {row['RANGO_ANIOS_BSE_MEJOR']}\")\n",
        "        print(f\"IDs: {row['ID_AUTADATA']} ‚Üî {row['ID_AUTODATA_BSE_MEJOR']}\")\n",
        "else:\n",
        "    print(\"   No hay registros en esta categor√≠a\")\n",
        "\n",
        "# Mostrar ejemplos de REVISION_HUMANA\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"EJEMPLOS DE 'REVISI√ìN HUMANA' (0.60 ‚â§ score ‚â§ 0.75)\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "revision = df_resultados[df_resultados['DECISION'] == 'REVISION_HUMANA'].sort_values('SCORE_MEJOR', ascending=False).head(5)\n",
        "if len(revision) > 0:\n",
        "    for idx, row in revision.iterrows():\n",
        "        print(f\"\\nScore: {row['SCORE_MEJOR']:.4f}\")\n",
        "        print(f\"Autodata: {row['MARCA_A']} | {row['MODELO_A']} | {row['ANIO_A']}\")\n",
        "        print(f\"Mejor:    {row['MARCA_BSE_MEJOR']} | {row['MODELO_BSE_MEJOR']} | {row['RANGO_ANIOS_BSE_MEJOR']}\")\n",
        "\n",
        "        # Mostrar candidatos alternos\n",
        "        if pd.notna(row['SCORE_CANDIDATO_2']):\n",
        "            print(f\"Alt. 2:   Score {row['SCORE_CANDIDATO_2']:.4f} | {row['MODELO_BSE_CANDIDATO_2']}\")\n",
        "        if pd.notna(row['SCORE_CANDIDATO_3']):\n",
        "            print(f\"Alt. 3:   Score {row['SCORE_CANDIDATO_3']:.4f} | {row['MODELO_BSE_CANDIDATO_3']}\")\n",
        "else:\n",
        "    print(\"   No hay registros en esta categor√≠a\")\n",
        "\n",
        "# Mostrar ejemplos de ALTA_NECESARIA\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"EJEMPLOS DE 'ALTA NECESARIA' (score < 0.60)\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "alta = df_resultados[df_resultados['DECISION'] == 'ALTA_NECESARIA'].head(5)\n",
        "if len(alta) > 0:\n",
        "    for idx, row in alta.iterrows():\n",
        "        print(f\"\\nScore: {row['SCORE_MEJOR']:.4f}\")\n",
        "        print(f\"Autodata: {row['MARCA_A']} | {row['MODELO_A']} | {row['ANIO_A']}\")\n",
        "        if pd.notna(row['MODELO_BSE_MEJOR']):\n",
        "            print(f\"Mejor (no confiable): {row['MODELO_BSE_MEJOR']}\")\n",
        "        else:\n",
        "            print(f\"Sin candidatos encontrados\")\n",
        "else:\n",
        "    print(\"No hay registros en esta categor√≠a\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4lK1ygKv9De"
      },
      "source": [
        "## 1Ô∏è‚É£2Ô∏è‚É£ Exportar resultados a CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nYvRTmiv9De"
      },
      "outputs": [],
      "source": [
        "# Exportar resultados completos\n",
        "archivo_salida = 'resultados_matching_bse_autodata.csv'\n",
        "df_resultados.to_csv(archivo_salida, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"Resultados exportados a: {archivo_salida}\")\n",
        "print(f\"Total de registros: {len(df_resultados):,}\")\n",
        "\n",
        "# Exportar solo registros para revisi√≥n humana\n",
        "archivo_revision = 'revision_humana_bse_autodata.csv'\n",
        "df_revision = df_resultados[df_resultados['DECISION'] == 'REVISION_HUMANA']\n",
        "df_revision.to_csv(archivo_revision, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"\\nArchivo de revisi√≥n humana: {archivo_revision}\")\n",
        "print(f\"Registros para revisar: {len(df_revision):,}\")\n",
        "\n",
        "# Exportar solo registros de alta necesaria\n",
        "archivo_alta = 'alta_necesaria_bse_autodata.csv'\n",
        "df_alta = df_resultados[df_resultados['DECISION'] == 'ALTA_NECESARIA']\n",
        "df_alta.to_csv(archivo_alta, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"\\nArchivo de alta necesaria: {archivo_alta}\")\n",
        "print(f\"Registros para dar de alta: {len(df_alta):,}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PROCESO COMPLETADO EXITOSAMENTE\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3TRU_YRv9Df"
      },
      "source": [
        "## 1Ô∏è‚É£3Ô∏è‚É£ (OPCIONAL) An√°lisis visual con gr√°ficos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAoitrn7v9Df"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configurar estilo\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "\n",
        "# Crear figura con subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "fig.suptitle('An√°lisis de Resultados - Matching BSE vs Autodata', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. Distribuci√≥n de decisiones\n",
        "decisiones_conteo.plot(kind='bar', ax=axes[0, 0], color=['green', 'orange', 'red'])\n",
        "axes[0, 0].set_title('Distribuci√≥n de Decisiones', fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Decisi√≥n')\n",
        "axes[0, 0].set_ylabel('Cantidad de registros')\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 2. Histograma de scores\n",
        "scores_completos = df_resultados['SCORE_MEJOR'].fillna(0)\n",
        "axes[0, 1].hist(scores_completos, bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0, 1].axvline(x=UMBRAL_EXISTE, color='green', linestyle='--', label=f'Umbral Existe ({UMBRAL_EXISTE})')\n",
        "axes[0, 1].axvline(x=UMBRAL_ALTA, color='red', linestyle='--', label=f'Umbral Alta ({UMBRAL_ALTA})')\n",
        "axes[0, 1].set_title('Distribuci√≥n de Scores de Similitud', fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Score')\n",
        "axes[0, 1].set_ylabel('Frecuencia')\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# 3. Boxplot de scores por decisi√≥n\n",
        "df_resultados.boxplot(column='SCORE_MEJOR', by='DECISION', ax=axes[1, 0])\n",
        "axes[1, 0].set_title('Distribuci√≥n de Scores por Decisi√≥n', fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Decisi√≥n')\n",
        "axes[1, 0].set_ylabel('Score')\n",
        "plt.sca(axes[1, 0])\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# 4. Top 10 marcas con m√°s registros\n",
        "top_marcas = df_resultados['MARCA_A'].value_counts().head(10)\n",
        "top_marcas.plot(kind='barh', ax=axes[1, 1])\n",
        "axes[1, 1].set_title('Top 10 Marcas (Autodata)', fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Cantidad de modelos')\n",
        "axes[1, 1].set_ylabel('Marca')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('analisis_matching.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Gr√°ficos generados y guardados como 'analisis_matching.png'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMs4nuBVv9Df"
      },
      "source": [
        "## 1Ô∏è‚É£4Ô∏è‚É£ (OPCIONAL) Ajustar umbrales interactivamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNDs_824v9Df"
      },
      "outputs": [],
      "source": [
        "def reclasificar_con_umbrales(df, umbral_existe, umbral_alta):\n",
        "    \"\"\"\n",
        "    Reclasifica los resultados con nuevos umbrales sin volver a ejecutar matching.\n",
        "    \"\"\"\n",
        "    df_nuevo = df.copy()\n",
        "\n",
        "    def nueva_decision(score):\n",
        "        if pd.isna(score) or score == 0:\n",
        "            return 'ALTA_NECESARIA'\n",
        "        elif score >= umbral_existe:\n",
        "            return 'YA_EXISTE'\n",
        "        elif score < umbral_alta:\n",
        "            return 'ALTA_NECESARIA'\n",
        "        else:\n",
        "            return 'REVISION_HUMANA'\n",
        "\n",
        "    df_nuevo['DECISION'] = df_nuevo['SCORE_MEJOR'].apply(nueva_decision)\n",
        "\n",
        "    # Mostrar nuevo resumen\n",
        "    print(f\"\\nNUEVO RESUMEN (Existe > {umbral_existe}, Alta < {umbral_alta})\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    nuevo_conteo = df_nuevo['DECISION'].value_counts()\n",
        "    total = len(df_nuevo)\n",
        "\n",
        "    for decision, count in nuevo_conteo.items():\n",
        "        porcentaje = (count / total) * 100\n",
        "        simbolo = {'YA_EXISTE': '‚úÖ', 'ALTA_NECESARIA': 'üÜï', 'REVISION_HUMANA': '‚ö†Ô∏è'}.get(decision, '‚ùì')\n",
        "        print(f\"{simbolo} {decision:20s}: {count:6,} ({porcentaje:5.2f}%)\")\n",
        "\n",
        "    return df_nuevo\n",
        "\n",
        "# Ejemplo: probar con umbrales m√°s conservadores\n",
        "print(\"Probando umbrales alternativos...\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"OPCI√ìN 1: Umbrales CONSERVADORES\")\n",
        "df_conservador = reclasificar_con_umbrales(df_resultados, umbral_existe=0.85, umbral_alta=0.50)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"OPCI√ìN 2: Umbrales AGRESIVOS\")\n",
        "df_agresivo = reclasificar_con_umbrales(df_resultados, umbral_existe=0.65, umbral_alta=0.55)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}