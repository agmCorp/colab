{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7T0gv58kGyue/1xJUDTIN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agmCorp/colab/blob/main/textSim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubhhpwUG27E6",
        "outputId": "d685524b-6d68-4232-f0ac-008593f13c13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pairwise similarities (debug):\n",
            "0 1 -> 0.505\n",
            "0 2 -> 0.575\n",
            "0 3 -> 0.405\n",
            "0 4 -> 0.678\n",
            "1 2 -> 0.345\n",
            "1 3 -> 0.400\n",
            "1 4 -> 0.469\n",
            "2 3 -> 0.612\n",
            "2 4 -> 0.406\n",
            "3 4 -> 0.371\n",
            "\n",
            "No matches found. Try lowering similarity_threshold (e.g. 0.70).\n"
          ]
        }
      ],
      "source": [
        "from typing import List, Tuple, Dict\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "def find_near_duplicates_char_ngrams(\n",
        "    texts: List[str],\n",
        "    top_k: int = 10,\n",
        "    similarity_threshold: float = 0.75,\n",
        "    analyzer: str = \"char\",\n",
        "    ngram_range: Tuple[int, int] = (2, 5),\n",
        ") -> List[Tuple[int, int, float]]:\n",
        "    \"\"\"\n",
        "    Devuelve pares (i, j, similarity) que parecen duplicados usando TF-IDF de n-gramas\n",
        "    de caracteres + similitud coseno.\n",
        "\n",
        "    - No usa normalización manual ni diccionario de equivalencias.\n",
        "    - \"analyzer\" puede ser \"char\" o \"char_wb\".\n",
        "    - similarity_threshold típico: 0.72 - 0.85 (calibrar según datos).\n",
        "    \"\"\"\n",
        "\n",
        "    if not texts:\n",
        "        return []\n",
        "\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        analyzer=analyzer,\n",
        "        ngram_range=ngram_range,\n",
        "        min_df=1,\n",
        "        lowercase=True,  # default, lo dejo explícito\n",
        "    )\n",
        "\n",
        "    X = vectorizer.fit_transform(texts)\n",
        "\n",
        "    # Vecinos más cercanos usando distancia coseno\n",
        "    n_neighbors = min(top_k + 1, len(texts))  # +1 porque el vecino 0 es el propio ítem\n",
        "    nn = NearestNeighbors(n_neighbors=n_neighbors, metric=\"cosine\")\n",
        "    nn.fit(X)\n",
        "\n",
        "    distances, indices = nn.kneighbors(X, return_distance=True)\n",
        "\n",
        "    # Guardar el mejor score por par (a,b)\n",
        "    best: Dict[Tuple[int, int], float] = {}\n",
        "\n",
        "    for i in range(len(texts)):\n",
        "        for rank in range(1, indices.shape[1]):  # rank 0 es el mismo i\n",
        "            j = int(indices[i, rank])\n",
        "            sim = 1.0 - float(distances[i, rank])  # similarity = 1 - cosine_distance\n",
        "            if sim >= similarity_threshold:\n",
        "                a, b = (i, j) if i < j else (j, i)\n",
        "                prev = best.get((a, b), 0.0)\n",
        "                if sim > prev:\n",
        "                    best[(a, b)] = sim\n",
        "\n",
        "    # Devolver ordenado por similitud descendente\n",
        "    out = [(a, b, s) for (a, b), s in best.items()]\n",
        "    out.sort(key=lambda x: x[2], reverse=True)\n",
        "    return out\n",
        "\n",
        "\n",
        "def print_pairwise_similarities(\n",
        "    texts: List[str],\n",
        "    analyzer: str = \"char\",\n",
        "    ngram_range: Tuple[int, int] = (2, 5),\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Debug: imprime similitudes coseno para todos los pares i<j.\n",
        "    Útil para elegir el threshold.\n",
        "    \"\"\"\n",
        "    if len(texts) < 2:\n",
        "        print(\"Need at least 2 texts.\")\n",
        "        return\n",
        "\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        analyzer=analyzer,\n",
        "        ngram_range=ngram_range,\n",
        "        min_df=1,\n",
        "        lowercase=True,\n",
        "    )\n",
        "    X = vectorizer.fit_transform(texts)\n",
        "    S = cosine_similarity(X)\n",
        "\n",
        "    for i in range(len(texts)):\n",
        "        for j in range(i + 1, len(texts)):\n",
        "            print(f\"{i} {j} -> {S[i, j]:.3f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    samples = [\n",
        "        \"CRUZE 5 1.4T LTZ PLUS EXTRA FULL 5P. AUT.\",\n",
        "        \"CRUZE automatic. 5 1.4T LTZ PLUS EXTRA FULL 5Puertas\",\n",
        "        \"CRUZE 1.4T LTZ PLUS EXTRA FULL 4P. AUT. (ARG)\",\n",
        "        \"CRUZE 1.4T 4 puertas LTZ PLUS EXTRA FULL AUT. (ARG)\",\n",
        "        \"CRUZE 5 1.4T LTZ PLUS EXTRA FULL 5Ptas AT.\",\n",
        "    ]\n",
        "\n",
        "    # 1) Debug opcional para ver scores y calibrar threshold\n",
        "    print(\"Pairwise similarities (debug):\")\n",
        "    print_pairwise_similarities(samples, analyzer=\"char\", ngram_range=(2, 5))\n",
        "    print()\n",
        "\n",
        "    # 2) Búsqueda de duplicados\n",
        "    hits = find_near_duplicates_char_ngrams(\n",
        "        samples,\n",
        "        top_k=5,\n",
        "        similarity_threshold=0.75,\n",
        "        analyzer=\"char\",\n",
        "        ngram_range=(2, 5),\n",
        "    )\n",
        "\n",
        "    if not hits:\n",
        "        print(\"No matches found. Try lowering similarity_threshold (e.g. 0.70).\")\n",
        "    else:\n",
        "        print(\"Matches:\")\n",
        "        for a, b, sim in hits:\n",
        "            print(f\"{sim:.3f} | {samples[a]}  <->  {samples[b]}\")\n"
      ]
    }
  ]
}