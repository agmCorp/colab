{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agmCorp/colab/blob/main/solucion4_matching_catalogos_bse_autodata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-8asNb1v9DU"
      },
      "source": [
        "# Sistema de Matching Optimizado v4: BSE vs Autodata\n",
        "\n",
        "## ¿Qué hace este notebook?\n",
        "\n",
        "Resuelve el problema de **vincular automáticamente dos catálogos de vehículos** que describen los mismos modelos con nomenclaturas distintas: el catálogo **BSE** (aprox. 33k registros) y el catálogo **Autodata** (aprox. 20k registros). Para cada registro de Autodata se encuentra el mejor equivalente en BSE, junto con un score de confianza [0, 1].\n",
        "\n",
        "### Proceso general\n",
        "\n",
        "1. **Preprocesamiento**: Ambos catálogos se normalizan para eliminar inconsistencias tipográficas, caracteres corruptos y variaciones de escritura. Se aplica un diccionario de sinónimos del dominio automotor (ej: `AA = A/A = aire acondicionado`, `TDI = TD Intercooler`, `5p = 5 puertas`, etc.) para que términos equivalentes queden representados con el mismo token antes de comparar. Los años erróneos del catálogo BSE (ej: `3020 → 2020`) también se corrigen en esta etapa.\n",
        "\n",
        "2. **Índices de búsqueda**: Se construyen tres índices sobre BSE para acelerar el matching: un índice por marca+año (filtrado rápido), embeddings vectoriales con el modelo BGE-M3 (similitud semántica) e índices BM25 por marca (similitud léxica).\n",
        "\n",
        "3. **Matching por registro**: Para cada registro Autodata se ejecuta un pipeline de tres fases:\n",
        "   - **Pre-filtrado**: se limita el espacio de búsqueda a registros BSE de la misma marca y año cercano (±2 → ±5 → toda la marca, en fallback progresivo).\n",
        "   - **Búsqueda híbrida**: se combinan similitud semántica (BGE-M3) y léxica (BM25) para obtener los 50 candidatos más prometedores.\n",
        "   - **Reranking**: un cross-encoder (BGE-Reranker-v2-m3) decide el orden final. El score resultante se convierte a [0,1] con una función sigmoid de temperatura calibrada automáticamente, y se penaliza según la distancia temporal entre el año del registro Autodata y el rango de años del candidato BSE.\n",
        "\n",
        "4. **Salida**: Para cada registro Autodata se reportan los 3 mejores candidatos BSE con su score, marca, modelo, rango de años, combustible y tipo. El resultado se exporta a CSV en dos formatos: completo (top-3) y resumido (mejor match solamente).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7NYKbNQv9DW"
      },
      "source": [
        "## 1️⃣ Instalación de dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8cGVOuBv9DW"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Instalar librerías necesarias\n",
        "!pip install -q sentence-transformers pandas numpy unidecode tqdm rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK3q5P_Uv9DX"
      },
      "source": [
        "## 2️⃣ Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aqx3mKPtv9DX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "from rank_bm25 import BM25Okapi\n",
        "from unidecode import unidecode\n",
        "import re\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"Librerías importadas correctamente\")\n",
        "print(f\"GPU disponible: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR96_ywjv9DY"
      },
      "source": [
        "## 3️⃣ Cargar los archivos CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyxupIjtv9DY"
      },
      "outputs": [],
      "source": [
        "# Cargar los datos (datatype str para evitar problemas de lectura)\n",
        "df_bse = pd.read_csv(\n",
        "    '/content/sample_data/CART_MATRICERO_BSE_202602190109.csv',\n",
        "    dtype=str,\n",
        "    keep_default_na=False\n",
        " )\n",
        "df_autodata = pd.read_csv(\n",
        "    '/content/sample_data/CART_PAD_AUTODATA_202602190107.csv',\n",
        "    dtype=str,\n",
        "    keep_default_na=False\n",
        " )\n",
        "\n",
        "print(f\"Registros BSE: {len(df_bse):,}\")\n",
        "print(f\"Registros Autodata: {len(df_autodata):,}\")\n",
        "print(\"\\nPrimeras filas de BSE:\")\n",
        "display(df_bse.head(10))\n",
        "print(\"\\nPrimeras filas de Autodata:\")\n",
        "display(df_autodata.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeKhuJ35v9DZ"
      },
      "source": [
        "## 4️⃣ Funciones de Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxrREbG0ulzd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Detecta caracteres fuera del rango ASCII estándar para anticipar problemas de encoding\n",
        "def detectar_caracteres_especiales(df, columna):\n",
        "    todos_los_textos = \" \".join(df[columna].astype(str).unique())\n",
        "    caracteres_raros = set(re.findall(r'[^a-zA-Z0-9\\s.,\\-\\/]', todos_los_textos))\n",
        "    return caracteres_raros\n",
        "\n",
        "print(\"Caracteres extraños en BSE:\", detectar_caracteres_especiales(df_bse, 'MODELO_ORIGINAL'))\n",
        "print(\"Caracteres extraños en Autodata:\", detectar_caracteres_especiales(df_autodata, 'MODELO_A_ORIGINAL'))\n",
        "\n",
        "def estandarizar_terminos_tecnicos(texto):\n",
        "    \"\"\"Normaliza sinónimos técnicos a tokens estándar únicos.\"\"\"\n",
        "    if not texto: return \"\"\n",
        "    # normalizar_texto aplica .lower() antes de invocar esta función\n",
        "    texto_procesado = texto\n",
        "\n",
        "    # c/ → \"con\" solo cuando lo que sigue es una letra, no un dígito.\n",
        "    # Esto evita alterar códigos de modelo con barra como \"C/200\" o \"C/220\".\n",
        "    texto_procesado = re.sub(r'\\bc\\s*/\\s*(?=[a-z])', ' con ', texto_procesado)\n",
        "    texto_procesado = re.sub(r'\\bp\\s*/\\s*', ' para ', texto_procesado)\n",
        "\n",
        "    mapeos = {\n",
        "        # AA, A/A, Aire y C/Aire son variantes del mismo equipamiento.\n",
        "        # \"C/Aire\" llega aquí ya transformado en \"con aire\" por la expansión de c/ anterior.\n",
        "        r\"\\baire\\s+acondicionado\\b|\\ba/a\\b|\\baa\\b|\\baire\\b|\\bcon aire\\b\": \" aire_acondicionado \",\n",
        "        r\"\\bclimatizador\\b|\\bclim\\b|\\bclimaut\\b\": \" climatizador \",\n",
        "        r\"\\bpas\\b|\\bpax\\b|\\bpasajeros\\b\": \" pasajeros \",\n",
        "        r\"\\bhb\\b|\\bhatchback\\b\": \" hatchback \",\n",
        "        r\"\\bsb\\b|\\bsportback\\b\": \" sportback \",\n",
        "        r\"\\be\\.full\\b|\\bex\\.full\\b|\\bextra full\\b\": \" extra_full \",\n",
        "        r\"\\bs\\.full\\b|\\bsuper full\\b\": \" super_full \",\n",
        "        r\"\\bcue\\b|\\bcuero\\b\": \" cuero \",\n",
        "        # Tech, Techo y T.Cielo designan el mismo equipamiento según especificación del negocio\n",
        "        r\"\\btech\\b|\\btecho\\b|\\bt\\.cielo\\b\": \" techo_solar \",\n",
        "        r\"\\bmb\\b|\\bmultim\\b|\\bmultimedia\\b\": \" multimedia \",\n",
        "        r\"\\bay\\.est\\b|\\bay\\.estac\\b|\\ba\\.estac\\b|\\bp\\.assi\\b|\\bp\\.assist\\b|\\bpark assist\\b\": \" ayuda_estacionamiento \",\n",
        "        r\"\\bllan\\b|\\bllantas\\b\": \" llantas \",\n",
        "        # turbo_diesel_intercooler debe ir antes de turbo_diesel para que \\btd\\b\n",
        "        # no consuma el \"td\" dentro de \"TD Intercooler\" antes de que el patrón compuesto pueda matchearlo\n",
        "        r\"\\btdi\\b|\\btd intercooler\\b|\\bt\\.diesel intercooler\\b|\\bturbo d intercooler\\b\": \" turbo_diesel_intercooler \",\n",
        "        r\"\\btd\\b|\\bt\\.diesel\\b|\\bturbo d\\b\": \" turbo_diesel \",\n",
        "        # \\baut\\. sin \\b final: el word boundary falla cuando el punto va seguido de espacio\n",
        "        # o fin de string, ya que tanto \".\" como \" \" son caracteres no-palabra y no existe\n",
        "        # boundary entre ellos. Tiptronic y S-Tronic se incluyen porque son transmisiones\n",
        "        # automáticas, aunque algunos registros no lo indiquen explícitamente con \"AUT\".\n",
        "        r\"\\btiptronic\\b|\\bs-tronic\\b|\\baut\\.|\\bautomatico\\b\": \" automatico \",\n",
        "        r\"\\b3-5p\\b|\\b3-5 ptas\\b|\\b3-5 puertas\\b\": \" 3_5_puertas \",\n",
        "        r\"\\b4-5p\\b|\\b4-5 ptas\\b|\\b4-5 puertas\\b\": \" 4_5_puertas \",\n",
        "        r\"(?<!-)(?:\\b2p\\b|\\b2 ptas\\b|\\b2 puertas\\b)\": \" 2_puertas \",\n",
        "        r\"(?<!-)(?:\\b3p\\b|\\b3 ptas\\b|\\b3 puertas\\b)\": \" 3_puertas \",\n",
        "        r\"(?<!-)(?:\\b4p\\b|\\b4 ptas\\b|\\b4 puertas\\b)\": \" 4_puertas \",\n",
        "        r\"(?<!-)(?:\\b5p\\b|\\b5 ptas\\b|\\b5 puertas\\b)\": \" 5_puertas \",\n",
        "        r\"\\badaptado a rural\\b|\\badaptada a rural\\b|\\bad\\.?\\s*rural\\b\": \" furgon_reformado \",\n",
        "        r\"\\blgo\\b|\\blargo\\b\": \" largo \",\n",
        "    }\n",
        "    for patron, reemplazo in mapeos.items():\n",
        "        texto_procesado = re.sub(patron, reemplazo, texto_procesado)\n",
        "    return texto_procesado\n",
        "\n",
        "def normalizar_texto(texto):\n",
        "    \"\"\"Repara caracteres extraños, unifica sinónimos y limpia símbolos.\"\"\"\n",
        "    if pd.isna(texto):\n",
        "        return \"\"\n",
        "\n",
        "    texto = str(texto).lower()\n",
        "\n",
        "    MAPA_REPARACION = {\n",
        "        \"á\": \"a\",\n",
        "        \"é\": \"e\",\n",
        "        \"í\": \"i\",\n",
        "        \"ó\": \"o\",\n",
        "        \"ú\": \"u\",\n",
        "        \"ñ\": \"n\",\n",
        "        \"ã¡\": \"a\",\n",
        "        \"ã©\": \"e\",\n",
        "        \"ã³\": \"o\",\n",
        "        \"ãº\": \"u\",\n",
        "        \"ã±\": \"n\",\n",
        "        \"ã\": \"i\",\n",
        "        \"¿\": \"o\",\n",
        "        \"±\": \"n\",\n",
        "        \"ý\": \"i\",\n",
        "        \"ß\": \"a\",\n",
        "        \"ð\": \"o\",\n",
        "        \"â\": \"a\",\n",
        "        \"²\": \"2\",\n",
        "        \"³\": \"3\",\n",
        "        \"¬\": \"\",\n",
        "        \"·\": \"\",\n",
        "        \"°\": \"\",\n",
        "        \"º\": \"\",\n",
        "        \"*\": \"\",\n",
        "        \"+\": \"\",\n",
        "        \"|\": \"\",\n",
        "        \")\": \"\",\n",
        "        '\"': \"\",\n",
        "        \"!\": \"\",\n",
        "        \"]\": \"\",\n",
        "        \"[\": \"\",\n",
        "        \"(\": \"\",\n",
        "        \"?\": \"\",\n",
        "        \"=\": \"\",\n",
        "    }\n",
        "\n",
        "    for error, correccion in MAPA_REPARACION.items():\n",
        "        texto = texto.replace(error, correccion)\n",
        "\n",
        "    texto = unidecode(texto)\n",
        "    texto = estandarizar_terminos_tecnicos(texto)\n",
        "\n",
        "    # Los tokens temporales protegen puntos decimales (ej: \"2,0\" → \"2.0\") y guiones\n",
        "    # internos (ej: \"4x4-full\") para que no se pierdan en la limpieza posterior de\n",
        "    # caracteres no alfanuméricos\n",
        "    decimal_token = \"_decimal_tok_\"\n",
        "    hyphen_token  = \"_hyphen_tok_\"\n",
        "\n",
        "    texto = re.sub(r\"(?<=\\d)[\\.,](?=\\d)\", decimal_token, texto)\n",
        "    texto = re.sub(r'(?<=[a-z0-9])-(?=[a-z0-9])', hyphen_token, texto)\n",
        "    texto = re.sub(r'(?<=[a-z0-9])/(?=[a-z0-9])', '_', texto)\n",
        "    texto = re.sub(r'\\s+-\\s+', ' ', texto)\n",
        "    texto = re.sub(r\"[^a-z0-9_\\s]\", \" \", texto)\n",
        "    texto = texto.replace(hyphen_token, '-')\n",
        "    texto = texto.replace(decimal_token, '.')\n",
        "    return re.sub(r\"\\s+\", \" \", texto).strip()\n",
        "\n",
        "# El catálogo BSE contiene años erróneos en dos rangos: mayores a 3000 (ej: 3020)\n",
        "# y en el rango 2985-2999 (ej: 2997). Todos corresponden a años reales menos 1000.\n",
        "# El umbral 2030 cubre ambos casos sin afectar años actuales válidos.\n",
        "ANIO_MAXIMO_VALIDO = 2030\n",
        "\n",
        "def corregir_anio_bse(anio):\n",
        "    \"\"\"Corrige años erróneos restándoles 1000 (ej: 3020 → 2020, 2997 → 1997).\"\"\"\n",
        "    if anio is None: return None\n",
        "    return anio - 1000 if anio > ANIO_MAXIMO_VALIDO else anio\n",
        "\n",
        "def extraer_anio_inicio_fin(rango_anios):\n",
        "    if pd.isna(rango_anios): return None, None\n",
        "    rango_str = str(rango_anios).strip()\n",
        "    match = re.findall(r'(\\d{4})', rango_str)\n",
        "    if len(match) >= 2:\n",
        "        return corregir_anio_bse(int(match[0])), corregir_anio_bse(int(match[1]))\n",
        "    elif len(match) == 1:\n",
        "        anio = corregir_anio_bse(int(match[0]))\n",
        "        return anio, anio\n",
        "    return None, None\n",
        "\n",
        "def normalizar_marca(texto):\n",
        "    if pd.isna(texto): return \"\"\n",
        "    texto = str(texto).lower()\n",
        "    texto = re.sub(r'<.*?>', '', texto)     # Elimina sufijos de país como <BRA>, <COL>\n",
        "    texto = unidecode(texto)                # Citroën -> Citroen\n",
        "    return texto.strip()\n",
        "\n",
        "# Tabla de equivalencias entre nombres de marca en Autodata y en BSE.\n",
        "# Necesaria porque algunos fabricantes aparecen con nombres distintos en cada catálogo\n",
        "# (ej: \"kia motors\" en Autodata → \"kia\" en BSE, \"dongfeng\" → dos variantes en BSE).\n",
        "ALIAS_MARCAS = {\n",
        "    \"polarsun\":         [\"polar sun\"],\n",
        "    \"routebuggy\":       [\"route buggy\"],\n",
        "    \"zhong tong\":       [\"zhongtong\"],\n",
        "    \"zxauto\":           [\"zx auto\"],\n",
        "    \"tongbao\":          [\"tong bao\"],\n",
        "    \"leapmotor\":        [\"leap motor\"],\n",
        "    \"kia motors\":       [\"kia\"],\n",
        "    \"byd auto\":         [\"byd\"],\n",
        "    \"bjc\":              [\"bjc-beijing\"],\n",
        "    \"gwm\":              [\"gwm - [great wall motor]\"],\n",
        "    \"gac - trumpchi\":   [\"gac\"],\n",
        "    \"lynk co\":          [\"lynk y co\"],\n",
        "    \"porsche replica\":  [\"porsche\"],\n",
        "    \"brilliance sunra\": [\"brilliance\"],\n",
        "    \"shineray\":         [\"shinerai\"],\n",
        "    \"fuqi\":             [\"fuqui\"],\n",
        "    \"dfsk\":             [\"dfm - dfsk (dong feng)\"],\n",
        "    \"chana\":            [\"chana-changan\"],\n",
        "    \"changan\":          [\"chana-changan\"],\n",
        "    \"geely riddara\":    [\"riddara (geely)\"],\n",
        "    \"dongfeng\":         [\"dfm - dfsk (dong feng)\", \"forthing (dongfeng)\"],\n",
        "    \"daewoo - fso\":     [\"daewoo\", \"fso\"],\n",
        "    \"vaz 1111 / uaz\":   [\"vaz\", \"uaz\"],\n",
        "}\n",
        "\n",
        "def resolver_marcas_bse(marca_auto_norm):\n",
        "    \"\"\"Resuelve una marca normalizada de Autodata a lista de marcas BSE equivalentes.\"\"\"\n",
        "    if marca_auto_norm in ALIAS_MARCAS:\n",
        "        return ALIAS_MARCAS[marca_auto_norm]\n",
        "    return [marca_auto_norm]\n",
        "\n",
        "def validar_normalizacion_contextual(df_bse, df_autodata, n_muestra=50):\n",
        "    \"\"\"Genera validación rápida con tabla de ejemplos y muestra real para revisión manual.\"\"\"\n",
        "    ejemplos = [\n",
        "        (\"c/diesel 2,0\",          \"con diesel 2.0\"),\n",
        "        (\"p/lancha x-line\",       \"para lancha x-line\"),\n",
        "        (\"S-TRONIC 3.3-3.8\",      \"automatico 3.3-3.8\"),\n",
        "        (\"USM-2450-74-ST\",        \"usm-2450-74-st\"),\n",
        "        (\"FULL - EXTRAFULL\",      \"full extrafull\"),\n",
        "        (\"DX/LX 4-5p\",            \"dx_lx 4_5_puertas\"),\n",
        "        (\"Adaptado a rural\",       \"furgon_reformado\"),\n",
        "        (\"ad. rural\",              \"furgon_reformado\"),\n",
        "        (\"AA 1.6\",                 \"aire_acondicionado 1.6\"),\n",
        "        (\"A/A 1.6\",                \"aire_acondicionado 1.6\"),\n",
        "        (\"C/Aire AUT.\",            \"aire_acondicionado automatico\"),\n",
        "        (\"SEDAN AUT. FULL\",        \"sedan automatico full\"),\n",
        "        (\"TECH 5P\",                \"techo_solar 5_puertas\"),\n",
        "        (\"TD Intercooler 4x4\",     \"turbo_diesel_intercooler 4x4\"),\n",
        "        (\"Turbo D Intercooler\",    \"turbo_diesel_intercooler\"),\n",
        "        (\"TDI 2.0\",                \"turbo_diesel_intercooler 2.0\"),\n",
        "        (\"TD 1.9\",                 \"turbo_diesel 1.9\"),\n",
        "    ]\n",
        "\n",
        "    df_ejemplos = pd.DataFrame(ejemplos, columns=['entrada', 'salida_esperada'])\n",
        "    df_ejemplos['salida_obtenida'] = df_ejemplos['entrada'].apply(normalizar_texto)\n",
        "    df_ejemplos['ok'] = df_ejemplos['salida_obtenida'] == df_ejemplos['salida_esperada']\n",
        "\n",
        "    serie_real = pd.concat([\n",
        "        df_bse['MODELO_ORIGINAL'].astype(str),\n",
        "        df_autodata['MODELO_A_ORIGINAL'].astype(str)\n",
        "    ], ignore_index=True).dropna().drop_duplicates()\n",
        "\n",
        "    n = min(n_muestra, len(serie_real))\n",
        "    df_revision = pd.DataFrame({'entrada_real': serie_real.sample(n=n, random_state=42)})\n",
        "    df_revision['salida_normalizada'] = df_revision['entrada_real'].apply(normalizar_texto)\n",
        "\n",
        "    return df_ejemplos, df_revision\n",
        "\n",
        "print(\"Funciones de preprocesamiento definidas\")\n",
        "print(f\"Alias de marcas configurados: {len(ALIAS_MARCAS)} reglas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21uFfU29v9Da"
      },
      "source": [
        "## 5️⃣ Preprocesamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZMFXDuav9Da"
      },
      "outputs": [],
      "source": [
        "print(\"Iniciando preprocesamiento de catálogos...\")\n",
        "\n",
        "# --- PROCESAR BSE ---\n",
        "df_bse['marca_norm'] = df_bse['MARCA'].apply(normalizar_marca)\n",
        "df_bse['modelo_norm'] = df_bse['MODELO_ORIGINAL'].apply(normalizar_texto)\n",
        "df_bse[['anio_inicio', 'anio_fin']] = df_bse['RANGO_ANIOS'].apply(\n",
        "    lambda x: pd.Series(extraer_anio_inicio_fin(x))\n",
        ")\n",
        "# Filtrar registros sin años procesables\n",
        "df_bse = df_bse[df_bse['anio_inicio'].notna()].copy()\n",
        "df_bse.reset_index(drop=True, inplace=True)  # IMPORTANTE: resetear índice para indexación consistente con embeddings\n",
        "\n",
        "# --- PROCESAR AUTODATA ---\n",
        "df_autodata['marca_norm'] = df_autodata['MARCA_A'].apply(normalizar_marca)\n",
        "df_autodata['modelo_norm'] = df_autodata['MODELO_A_ORIGINAL'].apply(normalizar_texto)\n",
        "# Año técnico para matching (derivado desde texto)\n",
        "df_autodata['anio'] = pd.to_numeric(df_autodata['ANIO_A'], errors='coerce').fillna(9999).astype(int)\n",
        "\n",
        "print(\"Preprocesamiento completado.\")\n",
        "print(f\"BSE limpio: {len(df_bse):,} registros | Autodata: {len(df_autodata):,} registros.\")\n",
        "\n",
        "print(\"\\nEjemplo de preprocesamiento:\")\n",
        "print(\"\\nBSE:\")\n",
        "display(df_bse[['MARCA', 'marca_norm', 'MODELO_ORIGINAL', 'modelo_norm', 'RANGO_ANIOS', 'anio_inicio', 'anio_fin']].head(10))\n",
        "print(\"\\nAutodata:\")\n",
        "display(df_autodata[['MARCA_A', 'marca_norm', 'MODELO_A_ORIGINAL', 'modelo_norm', 'ANIO_A', 'anio']].head(10))\n",
        "\n",
        "# Validación recomendada antes de ejecutar matching completo\n",
        "df_validacion_ejemplos, df_revision_50 = validar_normalizacion_contextual(df_bse, df_autodata, n_muestra=50)\n",
        "print(\"\\nValidación de ejemplos controlados:\")\n",
        "display(df_validacion_ejemplos)\n",
        "print(\"\\nMuestra de 50 casos reales para revisión manual:\")\n",
        "display(df_revision_50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbIu43lcv9Db"
      },
      "source": [
        "## 6️⃣ Cargar Modelos y Construir Índices Optimizados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6yz9P4CslvL"
      },
      "outputs": [],
      "source": [
        "# Detectar dispositivo para los modelos de IA (Transformers sí usarán GPU)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Usando device para IA: {device}\")\n",
        "\n",
        "# ========== 1. MODELOS DE IA ==========\n",
        "print(\"\\n[1/5] Cargando modelos de embeddings y reranker...\")\n",
        "# BGE-M3 genera los vectores y Reranker decide el mejor candidato\n",
        "model_bi = SentenceTransformer('BAAI/bge-m3', device=device)\n",
        "reranker = CrossEncoder('BAAI/bge-reranker-v2-m3', device=device)\n",
        "print(\"Modelos cargados\")\n",
        "\n",
        "# ========== 2. ÍNDICE POR MARCA + AÑO (Pre-filtrado inteligente) ==========\n",
        "print(\"\\n[2/5] Construyendo índice de marca-año para filtrado rápido...\")\n",
        "marca_anio_index = defaultdict(lambda: defaultdict(list))\n",
        "\n",
        "for idx, row in df_bse.iterrows():\n",
        "    marca = row['marca_norm']\n",
        "    try:\n",
        "        anio_ini = int(row['anio_inicio'])\n",
        "        anio_fin = int(row['anio_fin'])\n",
        "        for year in range(anio_ini, anio_fin + 1):\n",
        "            marca_anio_index[marca][year].append(idx)\n",
        "    except (ValueError, TypeError):\n",
        "        continue\n",
        "\n",
        "print(f\"Índice construido: {len(marca_anio_index)} marcas\")\n",
        "\n",
        "# ========== 3. EMBEDDINGS BSE (Búsqueda vectorial) ==========\n",
        "print(\"\\n[3/5] Generando embeddings BGE-M3 para BSE...\")\n",
        "bse_textos = (df_bse['marca_norm'] + \" \" + df_bse['modelo_norm']).tolist()\n",
        "\n",
        "bse_embeddings = model_bi.encode(\n",
        "    bse_textos,\n",
        "    convert_to_tensor=False,\n",
        "    batch_size=512,\n",
        "    show_progress_bar=True,\n",
        "    normalize_embeddings=True\n",
        ").astype('float32')\n",
        "\n",
        "print(f\"Embeddings generados: {bse_embeddings.shape[0]} vectores ({bse_embeddings.shape[1]}D)\")\n",
        "\n",
        "# ========== 4. ÍNDICES BM25 POR MARCA ==========\n",
        "print(\"\\n[4/5] Construyendo índices BM25 por marca...\")\n",
        "bm25_cache = {}\n",
        "marca_to_indices = defaultdict(list)\n",
        "\n",
        "for idx, row in df_bse.iterrows():\n",
        "    marca_to_indices[row['marca_norm']].append(idx)\n",
        "\n",
        "for marca, indices in tqdm(marca_to_indices.items(), desc=\"BM25 por marca\"):\n",
        "    corpus_marca = [str(df_bse.loc[i, 'modelo_norm']).split() for i in indices]\n",
        "    bm25_cache[marca] = {\n",
        "        'bm25': BM25Okapi(corpus_marca),\n",
        "        'indices': indices\n",
        "    }\n",
        "\n",
        "print(f\"{len(bm25_cache)} índices BM25 cacheados\")\n",
        "\n",
        "# ========== 5. PRE-ENCODING AUTODATA + CALIBRACIÓN SIGMOID ==========\n",
        "print(\"\\n[5/5] Pre-encoding de queries Autodata y calibración de temperatura...\")\n",
        "\n",
        "# 5a. Batch encoding de todos los textos Autodata\n",
        "# Evita encodear 1 query a la vez dentro del loop de matching (cuello de botella en GPU)\n",
        "autodata_textos = (df_autodata['marca_norm'] + \" \" + df_autodata['modelo_norm']).tolist()\n",
        "autodata_embeddings = model_bi.encode(\n",
        "    autodata_textos,\n",
        "    convert_to_tensor=False,\n",
        "    batch_size=512,\n",
        "    show_progress_bar=True,\n",
        "    normalize_embeddings=True\n",
        ").astype('float32')\n",
        "print(f\"Autodata embeddings pre-calculados: {autodata_embeddings.shape[0]} vectores ({autodata_embeddings.shape[1]}D)\")\n",
        "\n",
        "# 5b. Calibración automática de temperatura del sigmoid\n",
        "# Lógica: muestreamos pares (query Autodata → top-1 BM25 por marca) y observamos\n",
        "# la distribución de logits del reranker. Luego fijamos T tal que:\n",
        "#   sigmoid(p80_logit / T) ≈ 0.95  →  T = p80 / ln(19) ≈ p80 / 2.944\n",
        "# Esto garantiza que el 80% de los pares \"candidatos\" caigan en zona útil (> 0.5).\n",
        "CALIBRACION_N = 150\n",
        "pares_calibracion = []\n",
        "\n",
        "autodata_muestra = df_autodata[df_autodata['marca_norm'].apply(\n",
        "    lambda m: any(mb in marca_to_indices for mb in resolver_marcas_bse(m))\n",
        ")].sample(min(CALIBRACION_N * 2, len(df_autodata)), random_state=42).reset_index(drop=True)\n",
        "\n",
        "for _, row in autodata_muestra.iterrows():\n",
        "    if len(pares_calibracion) >= CALIBRACION_N:\n",
        "        break\n",
        "    marca_auto = row['marca_norm']\n",
        "    modelo_auto = row['modelo_norm']\n",
        "    anio_auto  = row['anio']\n",
        "    query_text = f\"{marca_auto} {modelo_auto}\"\n",
        "    for m in resolver_marcas_bse(marca_auto):\n",
        "        if m in bm25_cache:\n",
        "            bm25_scores = bm25_cache[m]['bm25'].get_scores(modelo_auto.split())\n",
        "            best_local  = int(np.argmax(bm25_scores))\n",
        "            best_idx    = bm25_cache[m]['indices'][best_local]\n",
        "            bse_text = (\n",
        "                f\"{df_bse.loc[best_idx, 'marca_norm']} \"\n",
        "                f\"{df_bse.loc[best_idx, 'modelo_norm']} \"\n",
        "                f\"{int(df_bse.loc[best_idx, 'anio_inicio'])}-{int(df_bse.loc[best_idx, 'anio_fin'])}\"\n",
        "            )\n",
        "            pares_calibracion.append([\n",
        "                f\"{query_text} {anio_auto if anio_auto != 9999 else ''}\",\n",
        "                bse_text\n",
        "            ])\n",
        "            break\n",
        "\n",
        "if pares_calibracion:\n",
        "    logits_cal = reranker.predict(pares_calibracion)\n",
        "    p10 = float(np.percentile(logits_cal, 10))\n",
        "    p50 = float(np.percentile(logits_cal, 50))\n",
        "    p80 = float(np.percentile(logits_cal, 80))\n",
        "    # Temperatura acotada a [0.3, 2.0] para evitar extremos\n",
        "    SIGMOID_TEMPERATURA = round(max(0.3, min(p80 / 2.944, 2.0)), 3) if p80 > 0.1 else 1.0\n",
        "    print(f\"\\nCalibración sobre {len(pares_calibracion)} pares:\")\n",
        "    print(f\"  Logits reranker — p10: {p10:.2f} | p50: {p50:.2f} | p80: {p80:.2f}\")\n",
        "    print(f\"  Temperatura sigmoid calibrada automáticamente: {SIGMOID_TEMPERATURA}\")\n",
        "else:\n",
        "    SIGMOID_TEMPERATURA = 1.0\n",
        "    print(\"Calibración no disponible. Temperatura por defecto: 1.0\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SISTEMA OPTIMIZADO LISTO\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL2PuZANv9Db"
      },
      "source": [
        "## 7️⃣ Función de Matching Optimizada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUj8ptC3s0Wi"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calcular_penalizacion_anio(anio_query, anio_ini_bse, anio_fin_bse):\n",
        "    \"\"\"\n",
        "    Penalización gradual según distancia temporal entre el año de Autodata y el rango BSE.\n",
        "    Cuanto mayor es la distancia, menor es el multiplicador aplicado al score final.\n",
        "    Retorna un multiplicador en [0.25, 1.0].\n",
        "    \"\"\"\n",
        "    if anio_query == 9999:   # Año desconocido en Autodata: penalización leve pero presente\n",
        "        return 0.9\n",
        "\n",
        "    if anio_ini_bse <= anio_query <= anio_fin_bse:\n",
        "        return 1.0  # El año cae dentro del rango BSE: sin penalización\n",
        "\n",
        "    distancia = (anio_ini_bse - anio_query) if anio_query < anio_ini_bse else (anio_query - anio_fin_bse)\n",
        "\n",
        "    if distancia == 1:    return 0.95\n",
        "    elif distancia == 2:  return 0.88\n",
        "    elif distancia == 3:  return 0.78\n",
        "    elif distancia <= 5:  return 0.65\n",
        "    elif distancia <= 10: return 0.45\n",
        "    else:                 return 0.25\n",
        "\n",
        "def sigmoid_temperatura(x, temperatura=1.0):\n",
        "    \"\"\"Convierte logits del reranker a [0,1] con escala calibrada para comparabilidad entre registros.\"\"\"\n",
        "    return 1.0 / (1.0 + np.exp(-x / temperatura))\n",
        "\n",
        "def encontrar_matches_optimizado(row_autodata, top_k=3, top_candidates=50, query_embedding=None):\n",
        "    \"\"\"\n",
        "    Pipeline de matching en 3 fases:\n",
        "    1. Pre-filtrado por marca + año con fallback progresivo (±2 → ±5 → toda la marca).\n",
        "    2. Búsqueda híbrida: similitud semántica (BGE-M3) + léxica (BM25).\n",
        "    3. Reranking con cross-encoder y penalización temporal aplicada sobre el score final.\n",
        "\n",
        "    El score resultante (score_comparable) es globalmente consistente entre registros,\n",
        "    lo que permite comparar la confianza de distintos matches entre sí.\n",
        "    \"\"\"\n",
        "    marca_auto  = row_autodata['marca_norm']\n",
        "    anio_auto   = row_autodata['anio']\n",
        "    modelo_auto = row_autodata['modelo_norm']\n",
        "    query_text  = f\"{marca_auto} {modelo_auto}\"\n",
        "\n",
        "    # ========== FASE 1: PRE-FILTRADO CON FALLBACK PROGRESIVO ==========\n",
        "    marcas_bse = resolver_marcas_bse(marca_auto)\n",
        "\n",
        "    # Se usa set comprehension para deduplicar índices cuando una marca tiene múltiples\n",
        "    # alias en BSE y varios de ellos apuntan al mismo registro\n",
        "    indices_marca = list({\n",
        "        idx\n",
        "        for m in marcas_bse\n",
        "        if m in marca_to_indices\n",
        "        for idx in marca_to_indices[m]\n",
        "    })\n",
        "\n",
        "    if not indices_marca:\n",
        "        return []\n",
        "\n",
        "    indices_candidatos = []\n",
        "    if anio_auto != 9999:\n",
        "        # Fallback progresivo por radio de año:\n",
        "        #   - ±2 años: conjunto más preciso y restrictivo\n",
        "        #   - ±5 años: ampliación si ±2 devuelve menos de 10 candidatos\n",
        "        # Se requieren al menos 10 candidatos para que la búsqueda híbrida y el reranker\n",
        "        # tengan suficiente variedad para discriminar correctamente.\n",
        "        # Si ningún radio alcanza ese mínimo, se usa el mejor resultado parcial encontrado\n",
        "        # (aunque sea < 10) en lugar de descartarlo. Solo si ambos radios devuelven exactamente\n",
        "        # 0 candidatos se cae al universo completo de la marca como último recurso.\n",
        "        mejor_candidatos_parciales = set()\n",
        "        for radio in [2, 5]:\n",
        "            candidatos_set = set()\n",
        "            for m in marcas_bse:\n",
        "                if m in marca_anio_index:\n",
        "                    for offset in range(-radio, radio + 1):\n",
        "                        year = anio_auto + offset\n",
        "                        if year in marca_anio_index[m]:\n",
        "                            candidatos_set.update(marca_anio_index[m][year])\n",
        "            if len(candidatos_set) >= 10:\n",
        "                indices_candidatos = list(candidatos_set)\n",
        "                break\n",
        "            # Conservar el resultado parcial más amplio por si ningún radio alcanza el mínimo\n",
        "            if len(candidatos_set) > len(mejor_candidatos_parciales):\n",
        "                mejor_candidatos_parciales = candidatos_set\n",
        "\n",
        "        if not indices_candidatos:\n",
        "            if mejor_candidatos_parciales:\n",
        "                indices_candidatos = list(mejor_candidatos_parciales)\n",
        "            else:\n",
        "                # Ningún año cercano encontró candidatos: usar todos los registros de la marca\n",
        "                indices_candidatos = indices_marca\n",
        "    else:\n",
        "        # Año desconocido: no es posible filtrar por rango temporal\n",
        "        indices_candidatos = indices_marca\n",
        "\n",
        "    if not indices_candidatos:\n",
        "        return []\n",
        "\n",
        "    # ========== FASE 2: BÚSQUEDA HÍBRIDA ==========\n",
        "    if query_embedding is not None:\n",
        "        q_emb = query_embedding.reshape(1, -1).astype('float32')\n",
        "    else:\n",
        "        q_emb = model_bi.encode([query_text], normalize_embeddings=True).astype('float32')\n",
        "\n",
        "    candidate_indices    = np.array(indices_candidatos)\n",
        "    candidate_embeddings = bse_embeddings[candidate_indices]\n",
        "    similarities         = np.dot(candidate_embeddings, q_emb.T).flatten()\n",
        "\n",
        "    # Se toma el doble de top_candidates en semántica para que BM25 tenga suficiente pool\n",
        "    # donde compensar casos donde el sentido semántico no es suficiente por sí solo\n",
        "    top_sem_count     = min(top_candidates * 2, len(candidate_indices))\n",
        "    top_sem_positions = np.argsort(similarities)[::-1][:top_sem_count]\n",
        "    semantic_results  = [(int(candidate_indices[pos]), float(similarities[pos])) for pos in top_sem_positions]\n",
        "\n",
        "    if not semantic_results:\n",
        "        return []\n",
        "\n",
        "    # BM25 léxico: complementa la búsqueda semántica para términos técnicos exactos\n",
        "    # (versiones, cilindradas, abreviaturas) donde la similitud vectorial puede fallar\n",
        "    bm25_dict       = {}\n",
        "    tokenized_query = modelo_auto.split()\n",
        "    for m in marcas_bse:\n",
        "        if m in bm25_cache:\n",
        "            bm25_data            = bm25_cache[m]\n",
        "            bm25_model           = bm25_data['bm25']\n",
        "            bm25_indices_locales = bm25_data['indices']\n",
        "            bm25_scores          = bm25_model.get_scores(tokenized_query)\n",
        "            if bm25_scores.max() > 0:\n",
        "                bm25_scores = bm25_scores / bm25_scores.max()  # Normalización al rango [0, 1]\n",
        "            for idx, score in zip(bm25_indices_locales, bm25_scores):\n",
        "                if idx not in bm25_dict or score > bm25_dict[idx]:\n",
        "                    bm25_dict[idx] = score\n",
        "\n",
        "    # Combinación ponderada: más peso a semántica (70%) que a léxico (30%).\n",
        "    # La penalización de año no se aplica aquí sino después del reranker,\n",
        "    # para no distorsionar la selección de candidatos en esta fase intermedia.\n",
        "    combined_scores = []\n",
        "    for idx, sem_score in semantic_results:\n",
        "        lex_score    = bm25_dict.get(idx, 0)\n",
        "        hybrid_score = 0.70 * sem_score + 0.30 * lex_score\n",
        "        combined_scores.append((idx, hybrid_score))\n",
        "\n",
        "    combined_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    top_hybrid = combined_scores[:top_candidates]\n",
        "\n",
        "    if not top_hybrid:\n",
        "        return []\n",
        "\n",
        "    # ========== FASE 3: RERANKING + SCORE COMPARABLE ==========\n",
        "    indices_finales   = [idx for idx, _ in top_hybrid]\n",
        "    hybrid_scores_raw = np.array([score for _, score in top_hybrid], dtype=float)\n",
        "\n",
        "    # El texto del par incluye el año de Autodata para que el reranker\n",
        "    # pueda considerarlo al comparar contra el rango de años BSE\n",
        "    pairs = [\n",
        "        [\n",
        "            f\"{query_text} {anio_auto if anio_auto != 9999 else ''}\",\n",
        "            f\"{df_bse.loc[idx, 'marca_norm']} {df_bse.loc[idx, 'modelo_norm']} \"\n",
        "            f\"{int(df_bse.loc[idx, 'anio_inicio'])}-{int(df_bse.loc[idx, 'anio_fin'])}\"\n",
        "        ]\n",
        "        for idx in indices_finales\n",
        "    ]\n",
        "\n",
        "    rerank_scores = reranker.predict(pairs)\n",
        "\n",
        "    # score_comparable combina reranker (85%) y score híbrido (15%).\n",
        "    # La sigmoid con temperatura calibrada convierte los logits del reranker a [0,1]\n",
        "    # de forma consistente entre registros, lo que permite comparar scores de distintas queries.\n",
        "    rerank_global    = sigmoid_temperatura(rerank_scores, temperatura=SIGMOID_TEMPERATURA)\n",
        "    hybrid_global    = np.clip(hybrid_scores_raw, 0, 1)\n",
        "    score_comparable = 0.85 * rerank_global + 0.15 * hybrid_global\n",
        "\n",
        "    # La penalización temporal se aplica sobre el score_comparable final para que tenga\n",
        "    # peso real en la decisión: un candidato temporalmente lejano queda efectivamente\n",
        "    # penalizado aunque su similitud de texto sea alta\n",
        "    year_penalties = np.array([\n",
        "        calcular_penalizacion_anio(\n",
        "            anio_auto,\n",
        "            df_bse.loc[idx, 'anio_inicio'],\n",
        "            df_bse.loc[idx, 'anio_fin']\n",
        "        )\n",
        "        for idx in indices_finales\n",
        "    ])\n",
        "    score_comparable = score_comparable * year_penalties\n",
        "\n",
        "    # Ordenar por score_comparable garantiza que el top_k retornado sea coherente\n",
        "    # y directamente comparable entre distintas queries\n",
        "    top_k_indices = np.argsort(score_comparable)[::-1][:top_k]\n",
        "\n",
        "    return [{\n",
        "        'ID_AUTODATA_BSE':  df_bse.loc[indices_finales[i], 'ID_AUTODATA_BSE'],\n",
        "        'score_comparable': round(float(score_comparable[i]), 4),\n",
        "        'marca_bse':        df_bse.loc[indices_finales[i], 'MARCA'],\n",
        "        'modelo_bse':       df_bse.loc[indices_finales[i], 'MODELO_ORIGINAL'],\n",
        "        'rango_anios_bse':  df_bse.loc[indices_finales[i], 'RANGO_ANIOS'],\n",
        "        'comb_bse':         df_bse.loc[indices_finales[i], 'COMB'],\n",
        "        'tipo_bse':         df_bse.loc[indices_finales[i], 'TIPO'],\n",
        "    } for i in top_k_indices]\n",
        "\n",
        "print(\"Función de matching optimizada definida\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_8ngLyev9Dc"
      },
      "source": [
        "## 8️⃣ Ejecutar matching para todo el catálogo Autodata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMcqJ78Cv9Dd"
      },
      "outputs": [],
      "source": [
        "\n",
        "TOP_K = 3\n",
        "resultados_finales = []\n",
        "\n",
        "print(f\"Iniciando matching de {len(df_autodata):,} registros...\")\n",
        "print(\"Estimado: ~30-40 minutos en T4 GPU (embeddings Autodata pre-calculados)\\n\")\n",
        "\n",
        "for enum_idx, (_, row) in enumerate(tqdm(df_autodata.iterrows(), total=len(df_autodata), desc=\"Matching\")):\n",
        "    matches = encontrar_matches_optimizado(\n",
        "        row,\n",
        "        top_k=TOP_K,\n",
        "        query_embedding=autodata_embeddings[enum_idx]\n",
        "    )\n",
        "\n",
        "    # Estructura base con valores vacíos para garantizar filas homogéneas en el DataFrame final,\n",
        "    # incluso para registros sin ningún match encontrado\n",
        "    res = {\n",
        "        'ID_AUTADATA':         row['ID_AUTADATA'],\n",
        "        'MARCA_A':             row['MARCA_A'],\n",
        "        'MODELO_A_ORIGINAL':   row['MODELO_A_ORIGINAL'],\n",
        "        'ANIO_A':              row['ANIO_A'],\n",
        "\n",
        "        'SCORE_COMPARABLE':    0.0,\n",
        "        'SCORE_1':             0.0,\n",
        "        'SCORE_2':             0.0,\n",
        "        'SCORE_3':             0.0,\n",
        "\n",
        "        'ID_AUTODATA_BSE_1':   'NO_MATCH',\n",
        "        'ID_AUTODATA_BSE_2':   '',\n",
        "        'ID_AUTODATA_BSE_3':   '',\n",
        "        'OBSERVACION':         '',\n",
        "\n",
        "        'MARCA_BSE_1':         '',\n",
        "        'MARCA_BSE_2':         '',\n",
        "        'MARCA_BSE_3':         '',\n",
        "\n",
        "        'MODELO_BSE_1':        '',\n",
        "        'MODELO_BSE_2':        '',\n",
        "        'MODELO_BSE_3':        '',\n",
        "\n",
        "        'RANGO_ANIOS_BSE_1':   '',\n",
        "        'RANGO_ANIOS_BSE_2':   '',\n",
        "        'RANGO_ANIOS_BSE_3':   '',\n",
        "\n",
        "        'COMB_BSE':            '',\n",
        "        'TIPO_BSE':            ''\n",
        "    }\n",
        "\n",
        "    if matches:\n",
        "        first_id = str(matches[0].get('ID_AUTODATA_BSE', '')).strip()\n",
        "        if first_id in ('', '0'):\n",
        "            res['OBSERVACION'] = 'MATCH_SIN_ID_BSE'\n",
        "\n",
        "        # SCORE_COMPARABLE refleja el score del mejor candidato (posición 1)\n",
        "        res['SCORE_COMPARABLE'] = matches[0].get('score_comparable', 0.0)\n",
        "\n",
        "        res['COMB_BSE']         = matches[0].get('comb_bse', '')\n",
        "        res['TIPO_BSE']         = matches[0].get('tipo_bse', '')\n",
        "\n",
        "        for i, m in enumerate(matches[:TOP_K]):\n",
        "            suffix = f\"_{i+1}\"\n",
        "            # Todos los scores reportados son score_comparable: globalmente consistentes entre registros\n",
        "            res[f'SCORE{suffix}']           = m['score_comparable']\n",
        "            res[f'ID_AUTODATA_BSE{suffix}'] = m['ID_AUTODATA_BSE']\n",
        "            res[f'MARCA_BSE{suffix}']       = m['marca_bse']\n",
        "            res[f'MODELO_BSE{suffix}']      = m['modelo_bse']\n",
        "            res[f'RANGO_ANIOS_BSE{suffix}'] = m['rango_anios_bse']\n",
        "    resultados_finales.append(res)\n",
        "\n",
        "df_resultados = pd.DataFrame(resultados_finales)\n",
        "\n",
        "# 'NO_MATCH' en ID_AUTODATA_BSE_1 es el centinela explícito de registros sin match.\n",
        "# Se evita usar SCORE_COMPARABLE == 0 porque matches reales de baja confianza también tienen score bajo.\n",
        "n_sin_match = (df_resultados['ID_AUTODATA_BSE_1'] == 'NO_MATCH').sum()\n",
        "n_con_match = (df_resultados['ID_AUTODATA_BSE_1'] != 'NO_MATCH').sum()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MATCHING COMPLETADO\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total procesado: {len(df_resultados):,} registros\")\n",
        "print(f\"Sin matches:     {n_sin_match:,}\")\n",
        "print(f\"Con matches:     {n_con_match:,}\")\n",
        "\n",
        "df_con_match = df_resultados[df_resultados['ID_AUTODATA_BSE_1'] != 'NO_MATCH']\n",
        "if len(df_con_match) > 0:\n",
        "    print(f\"\\nScore comparable promedio: {df_con_match['SCORE_COMPARABLE'].mean():.3f}\")\n",
        "\n",
        "display(df_resultados.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4lK1ygKv9De"
      },
      "source": [
        "## 9️⃣ Análisis de Calidad y Exportación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nYvRTmiv9De"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"\\nDISTRIBUCIÓN DE SCORE_COMPARABLE (GLOBAL):\\n\")\n",
        "\n",
        "# Se excluyen registros sin match para calcular estadísticas solo sobre matches válidos.\n",
        "# El criterio es ID_AUTODATA_BSE_1 != 'NO_MATCH' y no SCORE_COMPARABLE > 0,\n",
        "# porque matches de baja confianza también tienen scores bajos pero son válidos.\n",
        "df_con_match_global = df_resultados[df_resultados['ID_AUTODATA_BSE_1'] != 'NO_MATCH'].copy()\n",
        "\n",
        "# Si no hay ningún match en el dataset, quantile() sobre una Serie vacía fallaría\n",
        "if len(df_con_match_global) == 0:\n",
        "    print(\"No se encontraron matches en el dataset. No hay estadísticas de score disponibles.\")\n",
        "    print(f\"\\nSin match (NO_MATCH): {len(df_resultados):,}\")\n",
        "else:\n",
        "    p25 = df_con_match_global['SCORE_COMPARABLE'].quantile(0.25)\n",
        "    p50 = df_con_match_global['SCORE_COMPARABLE'].quantile(0.50)\n",
        "    p75 = df_con_match_global['SCORE_COMPARABLE'].quantile(0.75)\n",
        "\n",
        "    print(f\"Umbrales calculados sobre {len(df_con_match_global):,} registros con match:\")\n",
        "    print(f\"  p25 = {p25:.4f} | p50 = {p50:.4f} | p75 = {p75:.4f}\")\n",
        "    print(f\"  Temperatura sigmoid usada: {SIGMOID_TEMPERATURA}\\n\")\n",
        "\n",
        "    print(f\"Score >= {p75:.3f} (Alta confianza,    top 25%):     {(df_con_match_global['SCORE_COMPARABLE'] >= p75).sum():,}\")\n",
        "    print(f\"Score {p50:.3f}-{p75:.3f} (Media confianza, 50-75%):  {((df_con_match_global['SCORE_COMPARABLE'] >= p50) & (df_con_match_global['SCORE_COMPARABLE'] < p75)).sum():,}\")\n",
        "    print(f\"Score {p25:.3f}-{p50:.3f} (Revisión humana, 25-50%): {((df_con_match_global['SCORE_COMPARABLE'] >= p25) & (df_con_match_global['SCORE_COMPARABLE'] < p50)).sum():,}\")\n",
        "    print(f\"Score <  {p25:.3f} (Baja confianza,   bot 25%):     {(df_con_match_global['SCORE_COMPARABLE'] < p25).sum():,}\")\n",
        "    print(f\"\\nSin match (NO_MATCH): {(df_resultados['ID_AUTODATA_BSE_1'] == 'NO_MATCH').sum():,}\")\n",
        "\n",
        "archivo_salida = 'resultados_matching_completo_v4.csv'\n",
        "df_resultados.to_csv(archivo_salida, index=False, encoding='utf-8-sig')\n",
        "print(f\"\\nResultados exportados a: {archivo_salida}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"========= PROCESO COMPLETADO EXITOSAMENTE =========\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "977481c3"
      },
      "outputs": [],
      "source": [
        "\n",
        "columnas_origen = [\n",
        "    'ID_AUTADATA',\n",
        "    'ID_AUTODATA_BSE_1',\n",
        "    'SCORE_COMPARABLE',\n",
        "    'MARCA_A',\n",
        "    'MARCA_BSE_1',\n",
        "    'ANIO_A',\n",
        "    'RANGO_ANIOS_BSE_1',\n",
        "    'MODELO_A_ORIGINAL',\n",
        "    'MODELO_BSE_1',\n",
        "    'COMB_BSE',\n",
        "    'TIPO_BSE',\n",
        "    'OBSERVACION'\n",
        "]\n",
        "\n",
        "renombrar_columnas = {\n",
        "    'ID_AUTADATA':       'ID_AUTODATA',\n",
        "    'ID_AUTODATA_BSE_1': 'ID_AUTODATA_BSE',\n",
        "    'MARCA_BSE_1':       'MARCA_BSE',\n",
        "    'RANGO_ANIOS_BSE_1': 'RANGO_ANIOS_BSE',\n",
        "    'MODELO_A_ORIGINAL': 'MODELO_A',\n",
        "    'MODELO_BSE_1':      'MODELO_BSE'\n",
        "}\n",
        "\n",
        "df_filtrado = df_resultados[columnas_origen].rename(columns=renombrar_columnas).copy()\n",
        "print(\"DataFrame 'df_filtrado' creado con columnas finales estandarizadas.\")\n",
        "display(df_filtrado.head(10))\n",
        "\n",
        "archivo_filtrado_salida = \"resultados_matching_resumido_v4.csv\"\n",
        "df_filtrado.to_csv(archivo_filtrado_salida, index=False, encoding=\"utf-8-sig\")\n",
        "print(f\"DataFrame filtrado exportado a: {archivo_filtrado_salida}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bse.to_csv('debug_df_bse.csv', index=False, encoding='utf-8-sig')\n",
        "df_autodata.to_csv('debug_df_autodata.csv', index=False, encoding='utf-8-sig')\n",
        "df_validacion_ejemplos.to_csv('debug_df_validacion_ejemplos.csv', index=False, encoding='utf-8-sig')\n",
        "df_revision_50.to_csv('debug_df_revision_50.csv', index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(\"4 archivos exportados.\")"
      ],
      "metadata": {
        "id": "r_g-4z30NYOK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}